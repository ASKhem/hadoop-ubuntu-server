# ğŸ˜ Hadoop Docker Environment

> Entorno Hadoop containerizado completo para desarrollo y pruebas, listo para usar en minutos.

<div align="center">

![Hadoop Version](https://img.shields.io/badge/Hadoop-3.3.6-blue)
![Flume Version](https://img.shields.io/badge/Flume-1.11.0-green)
![Ubuntu Version](https://img.shields.io/badge/Ubuntu-22.04%20LTS-orange)
![License](https://img.shields.io/badge/license-Apache%202.0-red)
![CI/CD](https://img.shields.io/badge/CI/CD-GitHub%20Actions-blue)

</div>

## ğŸš€ CaracterÃ­sticas Principales

- âœ¨ **Hadoop 3.3.6** - Ãšltima versiÃ³n estable
- ğŸŒŠ **Apache Flume 1.11.0** - RecolecciÃ³n de datos en tiempo real
- ğŸ”„ **RotaciÃ³n automÃ¡tica de logs**
- ğŸ’¾ **Backup automÃ¡tico de HDFS**
- ğŸ“Š **MonitorizaciÃ³n de salud del sistema**
- âš¡ **GestiÃ³n automÃ¡tica de recursos**
- ğŸ”’ **Seguridad mejorada**
- ğŸ“ˆ **CI/CD integrado**

## ğŸ“‹ Requisitos Previos

| Componente | MÃ­nimo Requerido | Recomendado |
|------------|------------------|-------------|
| Docker     | 20.10+          | 23.0+       |
| RAM        | 4GB             | 8GB         |
| Disco      | 20GB            | 50GB        |
| CPU        | 2 cores         | 4 cores     |

## ğŸƒâ€â™‚ï¸ Inicio RÃ¡pido

1ï¸âƒ£ Clonar el repositorio
```bash
git clone https://github.com/ASKhem/hadoop-ubuntu-server.git
cd hadoop-ubuntu-server
```

2ï¸âƒ£ Configurar recursos (opcional)
```bash
# Editar variables en setup-hadoop.sh
MEMORY_LIMIT="4g"  # LÃ­mite de memoria
CPU_LIMIT="2"      # LÃ­mite de CPU
```

3ï¸âƒ£ Ejecutar el script de configuraciÃ³n
```bash
./setup-hadoop.sh
```

4ï¸âƒ£ Conectarse al contenedor
```bash
ssh -i id_rsa hadoopuser@localhost -p 22
```

## ğŸ”Œ Puertos y Servicios

| Puerto | Servicio                  | Healthcheck |
|--------|---------------------------|-------------|
| 22     | SSH                       | âœ…          |
| 9870   | HDFS NameNode Web UI      | âœ…          |
| 8088   | YARN ResourceManager UI   | âœ…          |
| 9000   | HDFS                      | âœ…          |
| 9864   | DataNode HTTP             | âœ…          |
| 41414  | Flume                     | âœ…          |

## ğŸ“ Estructura del Proyecto

```
hadoop-docker/
â”œâ”€â”€ ğŸ“‚ .github/
â”‚   â””â”€â”€ ğŸ“‚ workflows/        # ConfiguraciÃ³n CI/CD
â”œâ”€â”€ ğŸ“‚ conf/
â”‚   â”œâ”€â”€ ğŸ“‚ flume/           # ConfiguraciÃ³n Flume
â”‚   â”œâ”€â”€ ğŸ“‚ hadoop/          # ConfiguraciÃ³n Hadoop
â”‚   â””â”€â”€ ğŸ“‚ scripts/         # Scripts de utilidad
â”œâ”€â”€ ğŸ“„ Dockerfile           # DefiniciÃ³n multi-stage
â”œâ”€â”€ ğŸ“„ setup-hadoop.sh      # Script de configuraciÃ³n
â””â”€â”€ ğŸ“„ README.md           # DocumentaciÃ³n
```

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### LÃ­mites de Recursos

El contenedor estÃ¡ configurado con lÃ­mites de recursos para garantizar un rendimiento Ã³ptimo:

```bash
# LÃ­mites por defecto
--memory=4g           # LÃ­mite de memoria
--memory-swap=4g      # LÃ­mite de swap
--cpus=2             # LÃ­mite de CPU
```

Para modificar estos lÃ­mites, edita las variables en `setup-hadoop.sh`:

```bash
MEMORY_LIMIT="8g"    # Aumentar memoria
CPU_LIMIT="4"        # Aumentar CPU
```

### Backup y RestauraciÃ³n

#### Realizar Backup Manual

```bash
# Ejecutar backup
/opt/hadoop/scripts/backup-hdfs.sh

# Los backups se almacenan en:
/data/backups/YYYYMMDD_HHMMSS.tar.gz
```

#### Restaurar desde Backup

```bash
# Listar backups disponibles
ls -l /data/backups/

# Restaurar desde backup especÃ­fico
/opt/hadoop/scripts/restore-hdfs.sh /data/backups/20240315_120000.tar.gz
```

### MonitorizaciÃ³n

#### Healthchecks AutomÃ¡ticos

El sistema realiza verificaciones automÃ¡ticas de salud cada 30 segundos:

- âœ… Estado de servicios HDFS
- âœ… Disponibilidad de YARN
- âœ… Conectividad SSH
- âœ… Uso de recursos

#### Logs y DiagnÃ³stico

```bash
# Ver logs de Hadoop
tail -f /opt/hadoop/logs/hadoop-*.log

# Ver logs de backup
tail -f /var/log/hadoop/backup.log

# Ver logs de restauraciÃ³n
tail -f /var/log/hadoop/restore.log
```

## ğŸ” Troubleshooting

### Problemas Comunes

<details>
<summary>El contenedor no inicia</summary>

1. Verificar recursos disponibles:
```bash
docker stats
```

2. Verificar logs del contenedor:
```bash
docker logs askhadoopx
```

3. Comprobar lÃ­mites de recursos:
```bash
cat /sys/fs/cgroup/memory/memory.limit_in_bytes
```
</details>

<details>
<summary>NameNode no estÃ¡ disponible</summary>

1. Verificar estado del servicio:
```bash
hdfs haadmin -getServiceState nn1
```

2. Revisar logs especÃ­ficos:
```bash
tail -f /opt/hadoop/logs/hadoop-hadoopuser-namenode-*.log
```

3. Reiniciar servicio:
```bash
stop-dfs.sh && start-dfs.sh
```
</details>

<details>
<summary>Problemas de rendimiento</summary>

1. Verificar uso de recursos:
```bash
htop
```

2. Comprobar configuraciÃ³n de memoria:
```bash
grep -r "heap" /opt/hadoop/etc/hadoop/
```

3. Ajustar parÃ¡metros:
```bash
# Editar hadoop-env.sh
export HADOOP_HEAPSIZE=4096
```
</details>

### Mejores PrÃ¡cticas

1. **MonitorizaciÃ³n Regular**
   - Revisar logs diariamente
   - Configurar alertas para healthchecks
   - Monitorear uso de recursos

2. **Mantenimiento**
   - Realizar backups periÃ³dicos
   - Rotar logs regularmente
   - Actualizar componentes

3. **Seguridad**
   - Cambiar contraseÃ±as regularmente
   - Mantener actualizados los certificados
   - Revisar logs de acceso

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea tu rama (`git checkout -b feature/mejora`)
3. Commit tus cambios (`git commit -am 'AÃ±adir mejora'`)
4. Push a la rama (`git push origin feature/mejora`)
5. Abre un Pull Request

### GuÃ­a de ContribuciÃ³n

- âœ… AÃ±adir tests para nuevas funcionalidades
- âœ… Actualizar documentaciÃ³n
- âœ… Seguir estilo de cÃ³digo existente
- âœ… Mantener compatibilidad hacia atrÃ¡s

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia Apache 2.0. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

<div align="center">

**Â¿Necesitas ayuda?** [Abre un Issue](https://github.com/ASKhem/hadoop-ubuntu-server.git/issues) â€¢ [DocumentaciÃ³n](https://github.com/ASKhem/hadoop-ubuntu-server.git/wiki)

</div>
